{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: Recurrent Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instructions:\n",
    "Train a recurrent network using LSTM that solves the given function. Submit all of the notebooks for each of the metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a)\tLet N be the length of your last name. Let S = (N % 5) + 1. Generate 10000 samples of training data with lengths S up to S + 5. Generate 1000 samples with the same parameters for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)\tTrain a LSTM that solves the metrics: skewness, geometric mean, and harmonic mean of the generated data. Use a different notebook for each metrics. This means that each of the metrics will have their own generated data. Train the network such that a mean absolute error of the testing data is below 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c)\tFor each notebook, report the mean squared error, mean absolute error, and the decile errors. Decile errors refers to the 0, 10, 20, â€¦ 100th percentile of the errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy as sp\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import mean_absolute_error as mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStoppingAt(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, monitor='val_loss', value=0.00001, verbose=0):\n",
    "        super(tf.keras.callbacks.Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(self.monitor) <= self.value:\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------- settings input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S = 3\n",
      "solve for skew\n"
     ]
    }
   ],
   "source": [
    "mode_y = 'skew'\n",
    "N = len('Marohom')\n",
    "S = (N % 5) + 1 ;\n",
    "print('S = %s' % S)\n",
    "print('solve for %s' % mode_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------- data gen and prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 10_000\n",
    "N_TEST = 1_000\n",
    "MAX_TIMESTEPS = S + 5\n",
    "MASK_VALUE = -1\n",
    "\n",
    "train_X = np.random.uniform(size=(N_SAMPLES, MAX_TIMESTEPS, 1))\n",
    "train_L = np.random.randint(2, MAX_TIMESTEPS, N_SAMPLES)\n",
    "\n",
    "test_X = np.random.uniform(size=(N_TEST, MAX_TIMESTEPS, 1))\n",
    "test_L = np.random.randint(2, MAX_TIMESTEPS, N_TEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_SAMPLES):\n",
    "    train_X[i, train_L[i]:] = MASK_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(N_TEST):\n",
    "    test_X[i, test_L[i]:] = MASK_VALUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeList = ['skew','gmean','hmean']\n",
    "\n",
    "if mode_y == modeList[0]:\n",
    "    train_y = sp.stats.skew(np.ma.masked_array(train_X, train_X==MASK_VALUE),axis=1, bias=True)\n",
    "    test_y = sp.stats.skew(np.ma.masked_array(test_X, test_X==MASK_VALUE),axis=1, bias=True)\n",
    "elif mode_y == modeList[1]:\n",
    "    train_y = sp.stats.mstats.gmean(np.ma.masked_array(train_X, train_X==MASK_VALUE),axis=1)\n",
    "    test_y = sp.stats.mstats.gmean(np.ma.masked_array(test_X, test_X==MASK_VALUE),axis=1)\n",
    "elif mode_y == modeList[2]:\n",
    "    train_y = sp.stats.mstats.hmean(np.ma.masked_array(train_X, train_X==MASK_VALUE),axis=1)\n",
    "    test_y = sp.stats.mstats.hmean(np.ma.masked_array(test_X, test_X==MASK_VALUE),axis=1)\n",
    "else:\n",
    "    train_y = np.ma.masked_array(train_X, train_X==MASK_VALUE).std(axis=1).data\n",
    "    test_y = np.ma.masked_array(test_X, test_X==MASK_VALUE).std(axis=1).data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------- model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, None, 1)]         0         \n",
      "_________________________________________________________________\n",
      "masking (Masking)            (None, None, 1)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 15)          1020      \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 15)                1860      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 16        \n",
      "=================================================================\n",
      "Total params: 2,896\n",
      "Trainable params: 2,896\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_ = tf.keras.Input(shape=(None, 1))\n",
    "masked = tf.keras.layers.Masking(MASK_VALUE)(input_)\n",
    "lstm1 = tf.keras.layers.LSTM(15, return_sequences=True)(masked)\n",
    "lstm2 = tf.keras.layers.LSTM(15)(lstm1)\n",
    "output = tf.keras.layers.Dense(1)(lstm2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_, outputs=output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filepath = r'models/'\n",
    "modelPath = ['skew/','gmean/','hmean/']\n",
    "bestFilePath = r'models/best_model/' + modelPath[modeList.index(mode_y)]\n",
    "\n",
    "cbList = [\n",
    "    EarlyStoppingAt(monitor='val_mae', value=0.1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(bestFilePath, save_best_only=True)\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/25\n",
      " 9792/10000 [============================>.] - ETA: 0s - loss: 0.2611 - mae: 0.3672WARNING:tensorflow:From C:\\Users\\Alec\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: models/best_model/skew/assets\n",
      "10000/10000 [==============================] - 17s 2ms/sample - loss: 0.2568 - mae: 0.3636 - val_loss: 0.0586 - val_mae: 0.1965\n",
      "Epoch 2/25\n",
      " 9824/10000 [============================>.] - ETA: 0s - loss: 0.0404 - mae: 0.1565INFO:tensorflow:Assets written to: models/best_model/skew/assets\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.0401 - mae: 0.1559 - val_loss: 0.0306 - val_mae: 0.1342\n",
      "Epoch 3/25\n",
      " 9920/10000 [============================>.] - ETA: 0s - loss: 0.0253 - mae: 0.1168INFO:tensorflow:Assets written to: models/best_model/skew/assets\n",
      "10000/10000 [==============================] - 11s 1ms/sample - loss: 0.0253 - mae: 0.1168 - val_loss: 0.0242 - val_mae: 0.1162\n",
      "Epoch 4/25\n",
      " 9856/10000 [============================>.] - ETA: 0s - loss: 0.0216 - mae: 0.1052INFO:tensorflow:Assets written to: models/best_model/skew/assets\n",
      "10000/10000 [==============================] - 13s 1ms/sample - loss: 0.0216 - mae: 0.1050 - val_loss: 0.0207 - val_mae: 0.1052\n",
      "Epoch 5/25\n",
      " 9952/10000 [============================>.] - ETA: 0s - loss: 0.0203 - mae: 0.1017INFO:tensorflow:Assets written to: models/best_model/skew/assets\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0202 - mae: 0.1016 - val_loss: 0.0197 - val_mae: 0.1009\n",
      "Epoch 6/25\n",
      " 9952/10000 [============================>.] - ETA: 0s - loss: 0.0182 - mae: 0.0957INFO:tensorflow:Assets written to: models/best_model/skew/assets\n",
      "10000/10000 [==============================] - 12s 1ms/sample - loss: 0.0182 - mae: 0.0957 - val_loss: 0.0193 - val_mae: 0.1002\n",
      "Epoch 7/25\n",
      " 9952/10000 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0891INFO:tensorflow:Assets written to: models/best_model/skew/assets\n",
      "10000/10000 [==============================] - 10s 1ms/sample - loss: 0.0158 - mae: 0.0890 - val_loss: 0.0139 - val_mae: 0.0856\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train_X, train_y, validation_data = (test_X, test_y), callbacks=cbList, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ---------------- metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mseList = []\n",
    "for _ in range(1000):\n",
    "    err = mse(test_y[_], prediction[_])\n",
    "    mseList.append(err)\n",
    "\n",
    "maeList = []\n",
    "for _ in range(1000):\n",
    "    err = mae(test_y[_], prediction[_])\n",
    "    maeList.append(err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.013894\n",
      "Mean Absolute Error: 0.085636\n"
     ]
    }
   ],
   "source": [
    "print('Mean Squared Error: %f' % mse(test_y, prediction))\n",
    "print('Mean Absolute Error: %f' % mae(test_y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE 0th Percentile Error: 0.000000 \n",
      "MSE 10th Percentile Error: 0.000151 \n",
      "MSE 20th Percentile Error: 0.000548 \n",
      "MSE 30th Percentile Error: 0.001339 \n",
      "MSE 40th Percentile Error: 0.002475 \n",
      "MSE 50th Percentile Error: 0.003915 \n",
      "MSE 60th Percentile Error: 0.006308 \n",
      "MSE 70th Percentile Error: 0.010137 \n",
      "MSE 80th Percentile Error: 0.016375 \n",
      "MSE 90th Percentile Error: 0.034050 \n",
      "MSE 100th Percentile Error: 0.329885 \n"
     ]
    }
   ],
   "source": [
    "for _ in [0,10,20,30,40,50,60,70,80,90,100]:\n",
    "    print('MSE %ith Percentile Error: %f ' % (_,np.percentile(mseList, _)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE 0th Percentile Error: 0.000048 \n",
      "MAE 10th Percentile Error: 0.012290 \n",
      "MAE 20th Percentile Error: 0.023410 \n",
      "MAE 30th Percentile Error: 0.036592 \n",
      "MAE 40th Percentile Error: 0.049747 \n",
      "MAE 50th Percentile Error: 0.062572 \n",
      "MAE 60th Percentile Error: 0.079420 \n",
      "MAE 70th Percentile Error: 0.100684 \n",
      "MAE 80th Percentile Error: 0.127964 \n",
      "MAE 90th Percentile Error: 0.184527 \n",
      "MAE 100th Percentile Error: 0.574356 \n"
     ]
    }
   ],
   "source": [
    "for _ in [0,10,20,30,40,50,60,70,80,90,100]:\n",
    "    print('MAE %ith Percentile Error: %f ' % (_,np.percentile(maeList, _)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
